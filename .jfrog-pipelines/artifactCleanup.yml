valuesFilePath: ./values.yml
__globals:
  artifactCleanupWebhookName: &artifactCleanupWebhookName '{{ default "artifact_cleanup_webhook" .Values.artifactCleanup.metadata.artifactCleanupWebhookName }}'
  artifactCleanupPropertyBagName: &artifactCleanupPropertyBagName '{{ default "artifact_cleanup_property_bag" .Values.artifactCleanup.metadata.propertyBagResourceName }}'
  artifactCleanupCronTriggerName: &artifactCleanupCronTriggerName '{{ default "artifact_cleanup_cron_trigger" .Values.artifactCleanup.metadata.cronTriggerResourceName }}'
  dockerCleanupPropertyBagName: &dockerCleanupPropertyBagName '{{ default "docker_cleanup_property_bag" .Values.dockerCleanup.metadata.propertyBagResourceName }}'
  dockerCleanupCronTriggerName: &dockerCleanupCronTriggerName '{{ default "docker_cleanup_cron_trigger" .Values.dockerCleanup.metadata.cronTriggerResourceName }}'

  configuration: &configuration
    runtime:
      type: image
      image:
        auto:
          language: 'node'
          versions:
            - '16'
    jfrogCliVersion: '2'
    integrations:
      - name: {{ .Values.shared.input.jfrogTokenIntegration }}

  onStart: &onStart
    - |
      function validate_repos() {
        echo '===== VALIDATING INPUT REPOS ====='
        if [[ -z "${repos}" ]]; then
          echo 'Please provide at least one repo to proceed!'
          exit 1
        fi
      }
      function validate_time_interval() {
        echo '===== VALIDATING INPUT TIME INTERVAL ====='
        if [ "${timeInterval}" -le 0 ]; then
          echo 'timeInterval variable must have value 1 or more'
          exit 1
        fi
      }
      function validate_pace_time() {
        echo '===== VALIDATING INPUT PACE TIME ====='
        if [ "${paceTimeMS}" -lt 1000 ]; then
          echo 'paceTimeMS variable must have value 1000 or more'
          exit 1
        fi
      }
      function validate_max_repos() {
        echo '===== VALIDATING INPUT MAX REPOS ====='
        if [ "${maxRepos}" -le 0 ]; then
          echo 'maxRepos variable must have value 1 or more'
          exit 1
        fi
      }
      function validate_max_artifacts() {
        echo '===== VALIDATING INPUT MAX ARTIFACTS ====='
        if [ "${maxArtifacts}" -le 0 ]; then
          echo 'maxArtifacts variable must have value 1 or more'
          exit 1
        fi
      }
      function configure_artifactory() {
        echo '===== CONFIGURING ARTIFACTORY ====='
        jf c add --url ${int_{{ .Values.shared.input.jfrogTokenIntegration }}_url} --access-token ${int_{{ .Values.shared.input.jfrogTokenIntegration }}_accessToken}
        isArtifactoryOnline=$(jf rt ping)                
        if [[ $isArtifactoryOnline != 'OK' ]]; then
          echo 'Please check access token!'
          exit 1
        fi
      }
    - validate_repos
    - validate_time_interval
    - validate_pace_time
    - validate_max_repos
    - validate_max_artifacts
    - configure_artifactory

  onComplete: &onComplete
    - |
      if test -f "./report.csv"; then
        add_cache_files report.csv report.csv
      fi

resources:
  - name: *artifactCleanupWebhookName
    type: IncomingWebhook
    configuration:
      webhookName: *artifactCleanupWebhookName
  - name: *artifactCleanupPropertyBagName
    type: PropertyBag
    configuration:
      artifactsCount: 0
      runNumber: 0
  - name: *dockerCleanupPropertyBagName
    type: PropertyBag
    configuration:
      dockerArtifactsCount: 0
      runNumber: 0

  {{ if eq true .Values.artifactCleanup.controls.cron.enabled }}
- name: *artifactCleanupCronTriggerName
  type: CronTrigger
  configuration:
    interval: "{{ default "0 0 5 ? * 1" .Values.artifactCleanup.controls.cron.expression }}"
  {{ end }}

  {{ if eq true .Values.dockerCleanup.controls.cron.enabled }}
- name: *dockerCleanupCronTriggerName
  type: CronTrigger
  configuration:
    interval: "{{ default "0 0 5 ? * 1" .Values.dockerCleanup.controls.cron.expression }}"
  {{ end }}

pipelines:
  - name: {{ .Values.artifactCleanup.metadata.pipelineName }}
    configuration:
      <<: *configuration
      environmentVariables:
        readOnly:
          timeUnit:
            values: ['year', 'month', 'day', 'hour', 'minute']
            default: 'month'
            description: The unit of the time interval. year, month, day, hour or minute are allowed values. Default month.
          timeInterval:
            default: 1
            description: The time interval to look back before deleting an artifact. Default 1.
          searchOn:
            values: ['last_downloaded', 'created']
            default: 'last_downloaded'
            description: Parameter to choose the search condition. Defaults to search artifacts last downloaded before selected time.
          repos:
            default: '{{ .Values.artifactCleanup.controls.repos }}'
            description: A list of repositories to clean. This parameter is required.
          dryRun:
            default: '{{ default "true" .Values.artifactCleanup.controls.dryRun }}'
            values: ['true', 'false']
            description: If this parameter is passed, artifacts will not actually be deleted. Default false.
          paceTimeMS:
            default: {{ default 1000 .Values.artifactCleanup.controls.paceTimeMS }}
            description: The number of milliseconds to delay between delete operations. Default 0.
          maxRepos:
            default: {{ default 10 .Values.artifactCleanup.controls.maxRepos }}
            description: Maximum allowed repos to search
          maxArtifacts:
            default: {{ default 100 .Values.artifactCleanup.controls.maxArtifacts }}
            description: Maximum allowed artifacts to be deleted

      {{ if eq true .Values.artifactCleanup.controls.webhook.enabled }}
      inputResources:
        - name: *artifactCleanupWebhookName
      {{ end }}

      {{ if eq true .Values.artifactCleanup.controls.cron.enabled }}
      inputResources:
        - name: *artifactCleanupCronTriggerName
      {{ end }}
      outputResources:
        - name: *artifactCleanupPropertyBagName

    steps:
      - name: delete_artifacts
        type: Bash
        configuration:
          environmentVariables:
            INTERNAL_PROPERTY_BAG_RESOURCE_NAME: *artifactCleanupPropertyBagName
        execution:
          onStart: *onStart
          onExecute:
            - |
              function search() {                
                echo '{"files":[{"aql":{"items.find":{"type":"file","stat.downloaded":{"$lt":"${threshold_timestamp}"},"@cleanup.skip":{"$ne":"*"}}},"sortBy":["stat.downloaded","created"],"sortOrder":"asc"}]}' > plugin_search_template.aql
                echo 'const fs=require("fs");const ts=(new Date).getTime();const ti=parseInt(process.argv[3]);const tu=process.argv[4];const tuMins={year:12*30*24*60,month:30*24*60,day:24*60,hour:60,minute:1};const tt=`${ts-ti*tuMins[tu]*60*1e3}`;const aql=fs.readFileSync("plugin_search_template.aql",{encoding:"utf8"});const maxRepos=parseInt(process.argv[5]||0);const repos=process.argv[2];const rq=repos.split(",").splice(0,maxRepos).map(repo=>{return{repo:repo}});const st=process.argv[6];const aqlO=JSON.parse(aql);aqlO.files[0].aql["items.find"]["$or"]=rq;if(st==="created"){delete aqlO.files[0].aql["items.find"]["stat.downloaded"];aqlO.files[0].aql["items.find"]["created"]={$lt:"${threshold_timestamp}"}}fs.writeFileSync("plugin_search.aql",JSON.stringify(aqlO,null,1).replace("${threshold_timestamp}",tt));' > prepare_aql.js
                node prepare_aql.js ${repos} ${timeInterval} ${timeUnit} ${maxRepos} ${searchOn}                
                echo "===== Fetching artifacts not downloaded since ${timeInterval} ${timeUnit} from now ====="
                echo "Aql:"
                cat plugin_search.aql
                actionable_artifacts=$(jf rt s --spec=plugin_search.aql --limit ${maxArtifacts})
                if [[ -z "${actionable_artifacts}" ]]; then
                  echo "No matching artifacts found for cleanup!"
                  exit 1
                else
                  echo '===== Following artifacts found for cleanup ====='
                  echo ${actionable_artifacts} | jq -r '.[].path' > /tmp/actionable_artifact_paths.txt
                  cat /tmp/actionable_artifact_paths.txt
                fi
              }           
              function cleanup() {
                if [[ ${dryRun} == 'true' ]]; then                
                  echo '==== Artifact cleanup skipped in dry run mode. To delete the artifacts, please run the pipeline with dryRun set to false ===='
                else
                  echo "===== Initiating cleanup with delay of ${paceTimeMS}ms between each artifact ====="
                  echo "artifact_repo_path, deleted_at_timestamp, deleted_at" >> report.csv
              
                  artifactsCount=0
                  while read path; do
                    artifactsCount=$((artifactsCount+1))
                    echo "[Deleting Artifact] ${path}"
                    jf rt del "${path}"
                    echo "${path}, `date +%s`, `date`" >> report.csv
                    sleep $((paceTimeMS/1000))
                  done </tmp/actionable_artifact_paths.txt
              
                  write_output ${INTERNAL_PROPERTY_BAG_RESOURCE_NAME} artifactsCount="${artifactsCount}"
                  write_output ${INTERNAL_PROPERTY_BAG_RESOURCE_NAME} runNumber=${run_number}
                fi
              }
            - search
            - cleanup
          onComplete: *onComplete

  - name: {{ .Values.dockerCleanup.metadata.pipelineName }}
    configuration:
      <<: *configuration
      environmentVariables:
        readOnly:
          timeUnit:
            values: [ 'year', 'month', 'day', 'hour', 'minute' ]
            default: 'minute'
            description: The unit of the time interval. year, month, day, hour or minute are allowed values. Default month.
          timeInterval:
            default: 1
            description: The time interval to look back before deleting an artifact. Default 1.
          searchOn:
            values: [ 'last_downloaded', 'created' ]
            default: 'created'
            description: Parameter to choose the search condition. Defaults to search artifacts last downloaded before selected time.
          repos:
            default: '{{ .Values.dockerCleanup.controls.repos }}'
            description: A list of repositories to clean. This parameter is required.
          dryRun:
            default: '{{ default "true" .Values.dockerCleanup.controls.dryRun }}'
            values: [ 'true', 'false' ]
            description: If this parameter is passed, artifacts will not actually be deleted. Default false.
          paceTimeMS:
            default: {{ default 1000 .Values.dockerCleanup.controls.paceTimeMS }}
            description: The number of milliseconds to delay between delete operations. Default 0.
          maxRepos:
            default: {{ default 10 .Values.dockerCleanup.controls.maxRepos }}
            description: Maximum allowed repos to search
          maxArtifacts:
            default: {{ default 100 .Values.dockerCleanup.controls.maxArtifacts }}
            description: Maximum allowed artifacts to be deleted

      {{ if eq true .Values.dockerCleanup.controls.cron.enabled }}
      inputResources:
        - name: *dockerCleanupCronTriggerName
      {{ end }}
      outputResources:
        - name: *dockerCleanupPropertyBagName

    steps:
      - name: delete_docker_artifacts
        type: Bash
        configuration:
          environmentVariables:
            INTERNAL_PROPERTY_BAG_RESOURCE_NAME: *dockerCleanupPropertyBagName
        execution:
          onStart: *onStart
          onExecute:
            - |
              function search() {                
                echo '{"files":[{"aql":{"items.find":{"type":"file","name":"manifest.json","@artifactory.content-type":{"$match":"*docker.distribution.manifest*"},"stat.downloaded":{"$lt":"${threshold_timestamp}"}}},"sortBy":["stat.downloaded","created"],"sortOrder":"asc"}]}' > plugin_search_template.aql
                echo 'const fs=require("fs");const ts=(new Date).getTime();const ti=parseInt(process.argv[3]);const tu=process.argv[4];const tuMins={year:12*30*24*60,month:30*24*60,day:24*60,hour:60,minute:1};const tt=`${ts-ti*tuMins[tu]*60*1e3}`;const aql=fs.readFileSync("plugin_search_template.aql",{encoding:"utf8"});const maxRepos=parseInt(process.argv[5]||0);const repos=process.argv[2];const rq=repos.split(",").splice(0,maxRepos).map(repo=>{return{repo:repo}});const st=process.argv[6];const aqlO=JSON.parse(aql);aqlO.files[0].aql["items.find"]["$or"]=rq;if(st==="created"){delete aqlO.files[0].aql["items.find"]["stat.downloaded"];aqlO.files[0].aql["items.find"]["created"]={$lt:"${threshold_timestamp}"}}fs.writeFileSync("plugin_search.aql",JSON.stringify(aqlO,null,1).replace("${threshold_timestamp}",tt));' > prepare_aql.js
                node prepare_aql.js ${repos} ${timeInterval} ${timeUnit} ${maxRepos} ${searchOn}                
                echo "===== Fetching artifacts not downloaded since ${timeInterval} ${timeUnit} from now ====="
                echo "Aql:"
                cat plugin_search.aql
                actionable_artifacts=$(jf rt s --spec=plugin_search.aql --limit ${maxArtifacts})
                if [[ -z "${actionable_artifacts}" ]]; then
                  echo "No matching artifacts found for cleanup!"
                  exit 1
                else
                  echo '===== Following artifacts found for cleanup ====='
                  echo ${actionable_artifacts} | jq -r '.[].path' > /tmp/actionable_artifact_paths.txt
                  cat /tmp/actionable_artifact_paths.txt
                fi
              }           
              function cleanup() {
                if [[ ${dryRun} == 'true' ]]; then                
                  echo '==== Artifact cleanup skipped in dry run mode. To delete the artifacts, please run the pipeline with dryRun set to false ===='
                else
                  echo "===== Initiating cleanup with delay of ${paceTimeMS}ms between each artifact ====="
                  echo "artifact_repo_path, deleted_at_timestamp, deleted_at" >> report.csv

                  artifactsCount=0
                  while read path; do
                    artifactsCount=$((artifactsCount+1))
                    dockerRepoPath=$(echo "${path/\/manifest.json/""}")
                    echo "[Deleting Artifact] ${dockerRepoPath}"
                    jf rt del "${dockerRepoPath}"
                    echo "${dockerRepoPath}, `date +%s`, `date`" >> report.csv
                    sleep $((paceTimeMS/1000))
                  done </tmp/actionable_artifact_paths.txt

                  write_output ${INTERNAL_PROPERTY_BAG_RESOURCE_NAME} artifactsCount="${artifactsCount}"
                  write_output ${INTERNAL_PROPERTY_BAG_RESOURCE_NAME} runNumber=${run_number}
                fi
              }
            - search
            - cleanup
          onComplete: *onComplete